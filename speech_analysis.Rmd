---
title: "From Obama to Trump: Changes in Presidential Language in the U.S.A. (2013–2025)"
author: "Pablo Aísa, Diego Fernández and Irantzu Lamarca"
date: "2025-04-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Trump's second investiture in the United States began just a few months ago and has revolutionised the world as we know it with his various economic and social measures. What has probably been most striking is the tone he has used to refer to other countries and their relationship with the United States. Trump's figure and his discourse were already known worldwide since he won the election in 2017, but the scene has been changing over the years. With his rapprochement with Russia in the Ukraine war and his direct confrontation with the European Union and China, Western relations in recent years have been weakened in recent months.

For this reason, we have decided to focus this paper on analysing the speeches of recent presidents in the US Congress. In this way, we want to see what differences there are between the speeches of the three presidents (Donald Trump, Joe Biden and Barack Obama) and to see specifically how Donald Trump in 2025 differs from the rest.

It would indeed have been more appropriate to use the inaugural speeches that different presidents make once they have won the elections and are sworn in as such. However, these speeches are generally shorter. For this reason, we have chosen to select the first speeches made by each of the presidents in their presentation to Congress.

-   [Remarks by the President in the State of the Union Address, Obama 2013](https://obamawhitehouse.archives.gov/the-press-office/2013/02/12/remarks-President-state-union-address)
-   [Remarks by President Trump in Joint Address to Congress 2017](https://trumpwhitehouse.archives.gov/briefings-statements/remarks-president-trump-joint-address-congress/)
-   [Remarks by President Biden in Address to a Joint Session of Congress 2021](https://bidenwhitehouse.archives.gov/briefing-room/speeches-remarks/2021/04/29/remarks-by-president-biden-in-address-to-a-joint-session-of-congress/)
-   [Remarks by President Trump in Joint Address to Congress 2025](https://www.whitehouse.gov/remarks/2025/03/remarks-by-president-trump-in-joint-address-to-congress/)

In order to be able to analyse these texts as comprehensively as possible, we will use three text analysis techniques. The three techniques chosen are: *Sentiment Analysis*, *Term Frequency* and *Topic Modeling*. These tools will be used separately, but will be presented together at the end of the work in order to draw conclusive results on the different discourses.

## Libraries

Firstly, we load the libraries that will be used in this project.

```{r}
library(tidyverse)
library(readr)
library(tidytext)
library(tm)
library(topicmodels)
library(SnowballC)
library(textdata)
library(scales)
library(knitr)
library(kableExtra)
library(proxy)
```

We will use these libraries for: 
- Manipulate and clean up text (tidyverse, tidytext)
- Remove empty words and prepare textual data (tm, SnowballC)
- Apply topic models as LDA (topicmodels)
- Visualize and present results (scales, knitr, kableExtra)

## Data cleaning

The first step will consist on obtaining the data and cleaning it to be able to further process the texts. The different speeches selected were prepared and transformed into a *.txt document* so they can be easily read in *Rstudio*.

### Trump 2025

We start with the last speech available which is the one that Trump made at the beginning of March 2025.

```{r}
# We remove the parts where the president was not talking
trump2025 <- read_lines("data/Trump_2025")

trump2025_filtered <- trump2025 %>%
  str_subset("^(AUDIENCE|SPEAKER|VICE PRESIDENT|REPRESENTATIVE GREEN|SPEAKER jOHNSON)", negate = TRUE)

# we remove the parenthesis
trump2025_filtered <- trump2025_filtered %>%
  str_replace_all("\\(.*?\\)", "")

# we remove "THE PRESIDENT:"
final_text_2025 <- str_replace(trump2025_filtered, "^THE PRESIDENT:\\s*", "")
# we remove empty rows
final_text_2025 <- final_text_2025[nchar(trimws(final_text_2025)) > 0]

```

Now we apply the same changes to the rest of the documents.

### Trump 2017

```{r}
# We remove the parts where the president was not talking
trump2017 <- read_lines("data/Trump_2017")

trump2017_filtered <- trump2017 %>%
  str_subset("^(AUDIENCE|SPEAKER|VICE PRESIDENT|REPRESENTATIVE GREEN|SPEAKER jOHNSON)", negate = TRUE)

# we remove the parenthesis
trump2017_filtered <- trump2017_filtered %>%
  str_replace_all("\\(.*?\\)", "")

# we remove "THE PRESIDENT:"
final_text_2017 <- str_replace(trump2017_filtered, "^THE PRESIDENT:\\s*", "")
# we remove empty rows
final_text_2017 <- final_text_2017[nchar(trimws(final_text_2017)) > 0]

```

### Biden 2021

```{r}
# We remove the parts where the president was not talking
biden2021 <- read_lines("data/Biden_2021")

biden2021_filtered <- biden2021 %>%
  str_subset("^(AUDIENCE|SPEAKER|VICE PRESIDENT|REPRESENTATIVE GREEN|SPEAKER jOHNSON)", negate = TRUE)

# we remove the parenthesis
biden2021_filtered <- biden2021_filtered %>%
  str_replace_all("\\(.*?\\)", "")

# we remove "THE PRESIDENT:"
final_text_2021 <- str_replace(biden2021_filtered, "^THE PRESIDENT:\\s*", "")
# we remove empty rows
final_text_2021 <- final_text_2021[nchar(trimws(final_text_2021)) > 0]
```

### Obama 2013

```{r}
# We remove the parts where the president was not talking
obama2013 <- read_lines("data/Obama_2013")

obama2013_filtered <- obama2013 %>%
  str_subset("^(AUDIENCE|SPEAKER|VICE PRESIDENT|REPRESENTATIVE GREEN|SPEAKER jOHNSON)", negate = TRUE)

# we remove the parenthesis
obama2013_filtered <- obama2013_filtered %>%
  str_replace_all("\\(.*?\\)", "")

# we remove "THE PRESIDENT:"
final_text_2013 <- str_replace(obama2013_filtered, "^THE PRESIDENT:\\s*", "")
# we remove empty rows
final_text_2013 <- final_text_2013[nchar(trimws(final_text_2013)) > 0]

```

## Text processing

### Sentiment analysis

### Term frequency

The next tool used in the analysis is *term frequency* (TF), which measures how often a word appears in a document. However, to better capture the relevance of words across multiple documents, we will also use *inverse document frequency* (IDF), which reduces the weight of terms that are common across many texts. By combining both, we obtain *TF-IDF*, a metric that highlights words that are not only frequent in a given document but also distinctive compared to the rest of the corpus. This helps us identify terms that are truly characteristic of each speech.

#### Most frequently used words

We start by analysing the most often used words. Firstly we will obtain the most frequent words in the whole speeches and then the total number of words per president.

```{r}
# Transform the texts into one character
obama2013 <- paste(final_text_2013, collapse = " ")
trump2017 <- paste(final_text_2017, collapse = " ")
biden2021 <- paste(final_text_2021, collapse = " ")
trump2025 <- paste(final_text_2025, collapse = " ")

# We create the tibble
speech <- tibble(
  year = as.factor(c(2013, 2017, 2021, 2025)),
  text = c(obama2013, trump2017, biden2021, trump2025))

# Tokenization
speech_total <- speech %>%
  unnest_tokens(word, text) %>%
  count(word, sort = TRUE)

speech_total
```

Now we have a dataframe with the number of times each word appears in all the texts available. The next step is to obtain the number of times the words appear in each speech.

```{r}
speech_words <- speech %>%
  unnest_tokens(word, text) %>%
  count(year, word, sort = TRUE)
```

In order to be able to proceed further with the analysis of term frequency, we sum up the total number of words in each speech. Then we have to add these numbers to the dataframe created to use them in the following steps.

In this case we have not filtered out the stop words as they are necessary to obtain the total number of words in each of the texts.

```{r}
total_words <- speech_words %>% 
  group_by(year) %>% 
  summarize(total = sum(n)) # Number of words per speech

speech_words <- left_join(speech_words, total_words) 
# We keep all the variables in the df
speech_words
```

With this information we can now obtain the term frequency distribution for each of the speeches we have selected. This data is obtained by dividing the number of times a word appears in a text divided by the total number of terms (words) in that text.

```{r}
speech_words <- speech_words %>%
  # We add a column for term_frequency
  mutate(term_frequency = n/total)

speech_words
```

Let's make a plot to see how words are distributed in each discourse.

```{r}
ggplot(speech_words, aes(term_frequency, fill = year)) +
  geom_histogram(show.legend = TRUE) +
  facet_wrap(~ year, ncol = 2, scales = "free_y") +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal()
```

As can be seen, there is a similar distribution for all years: most words have very low frequencies and a few words have very high frequencies.

Let's look at the distribution of less frequent words.

```{r}
ggplot(speech_words, aes(term_frequency, fill = year)) +
  geom_histogram(show.legend = TRUE) +
  xlim(NA, 0.001) +
  facet_wrap(~ year, ncol = 2, scales = "free_y") +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal()
```

The distribution seems to remain very similar for all speeches, with the number of words decreasing with increasing frequency.

Once we have been able to work with the term frequency tool, we can move forward using a number of other measures that can help us to learn more about these texts.

#### Zipf's Law

The next tool that we will use is the *Zipf’s Law*. This law states that a word’s frequency is inversely proportional to its rank in a frequency list: the most common words appear most often, while rare words have higher ranks and appear less frequently.

Let's create a new dataframe for our data with a new column that ranks the words in descending order by their term frequency.

```{r}
freq_by_rank <- speech_words %>% 
  group_by(year) %>% 
  mutate(rank = row_number()) %>%
  ungroup()

freq_by_rank
```

Let's visualise in a line graph the inversely proportional relationship between TF and the rank of the words we are working with.

```{r}
freq_by_rank %>% 
  ggplot(aes(rank, term_frequency, color = year)) + 
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10() +
  scale_color_brewer(palette = "Set2") +
  theme_minimal()
```

The logarithmic scale shows that there is a constant negative slope. However, as it can be seen, there are some slight differences in the distributions of the four discourses. To understand these variations, we need to divide the graph into three parts and analyse them separately.

It seems that the central part is the most stable, as it is where all the distributions coincide the most. In order to better analyse the texts, we will create a linear regression model using this central section and then display it in the graph. In this way, we use this section as a normal use of the language and we can check how much the other sections differ.

```{r}
rank_subset <- freq_by_rank %>% # We store the section in a new variable
  filter(rank < 400,
         rank > 10) # Ranks between 400 and 10

# We use the linear model function
lm(log10(term_frequency) ~ log10(rank), data = rank_subset)

# We visualize it on the graph by adding a reference line
freq_by_rank %>% 
  ggplot(aes(rank, term_frequency, color = year)) + 
  geom_abline(intercept = -0.62, slope = -1.1, 
              color = "gray30", linetype = 2) +
  geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10() +
  scale_color_brewer(palette = "Set2") +
  theme_minimal()
  
```

The most important thing to note in this graph is that less frequent words appear more frequently in these discourses. It may imply that these speeches are either very issue-specific or use more artificial language as a political tool. We will take this into account for the next steps.

#### Obtaining the TF-IDF

The next step is to obtain the IDF and then combine it with the term frequency measure. To do this, we just have to apply the *bind_tf_idf* from the *tidytext* package to our dataset.

```{r}
speech_tf_idf <- speech_words %>%
  bind_tf_idf(word, year, n) %>% # We obtain three new columns
  select(-term_frequency) # We can drop the TF that we had before 

speech_tf_idf
```

The first words that appear have a TF-IDF close to zero because they are used so often. It can be observed that these are the same words for the four discourses analysed (*for*, *and*, *the*, *of*...).

Let's sort them in descending order according to the TF-IDF measure to see the strangest words in the whole collection.

```{r}
sorted_tf_idf <- speech_tf_idf %>%
  select(-total) %>% # This column is not necessary anymore
  arrange(desc(tf_idf))

sorted_tf_idf
```

What is most striking is the number of times Trump uses the adverb *very* in 2025. On the other hand, as the date is very close to the Covid-19 pandemic, it is logical to see that Biden in 2021 is by far the one who uses the word *pandemic* the most.

In order to better observe the differences between the four speeches, we will group the words by year and thus obtain the 10 most special words of each of them in comparison with the rest.

```{r}
# Modify the titles of each graph
president <- c(
  "2013" = "Obama (2013)",
  "2017" = "Trump (2017)",
  "2021" = "Biden (2021)",
  "2025" = "Trump (2025)")

# We create the plot
plot_speech <- speech_tf_idf %>% 
  group_by(year) %>% 
  slice_max(tf_idf, n = 10) %>% 
  ungroup() %>%
  mutate(word = reorder(word, tf_idf)) %>%
  ggplot(aes(tf_idf, word, fill = year)) +
  geom_col(show.legend = FALSE) +
  labs(x = "tf-idf", y = NULL) +
  facet_wrap(~ year, ncol = 2, 
             scales = "free",
             # President and year for the titles
             labeller = labeller(year = president)) +
  # We modify the limits to compare better the differences
  scale_x_continuous(limits = c(0, 0.0025)) +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 10, face = "bold"),
    strip.text = element_text(size = 10, face = "bold"))

plot_speech
```

As can be seen in these bar plots, the conclusions are similar to those previously discussed. Analysing each speech separately, it is striking that Obama in 2013 uses initiative-laden language using words such as let's or encourage. On the other hand, Biden's speech in 2021 is loaded with mentions of covid and vaccines, although the importance of guns is also very relevant.

On the other hand, analysing Trump's speeches separately also allows for some very relevant conclusions. The first thing that stands out in the 2017 speech is the multiple mentions of [*Obamacare*](https://www.usa.gov/es/salud-mercado-seguros-medicos-aca) and health insurance. These data denote a clear criticism of Barack Obama's previous government, which is complemented by personal stories using personal names (which also appear in the most relevant words of this speech). In 2025 it highlights the importance he attaches in his speech to Ukraine and to the tariff measures he had previously announced. The rest of the words do not provide us with much more information beyond being words that we need to understand in context.

With the sentiment analysis and term frequency tools, we were able to get an idea of the content and characteristics of the discourses. However, it is necessary to supplement these results with topic modelling in order to draw more developed conclusions.

### Topic modeling

We will start by analyzing Trump's speeches, for being able to compare them to the other president's speeches later on. 

#### Trump 2017 speech

We first need to clean the text and make it in a suitable format for practising topic modeling. 

```{r}

# We remove the parts where the president was not talking
trump2017 <- read_lines("data/Trump_2017")

texto_filtrado_2017 <- trump2017 %>%
  str_subset("^(AUDIENCE|SPEAKER|VICE PRESIDENT|REPRESENTATIVE GREEN|SPEAKER jOHNSON)", negate = TRUE)
texto_filtrado_2017

# we remove the parenthesis
texto_filtrado_2017 <- texto_filtrado_2017 %>%
  str_replace_all("\\(.*?\\)", "")
texto_filtrado_2017

# we remove "THE PRESIDENT:"
texto_final_2017 <- str_replace(texto_filtrado_2017, "^THE PRESIDENT:\\s*", "")
texto_final_2017

# we remove empty rows
texto_final_2017 <- texto_final_2017[nchar(trimws(texto_final_2017)) > 0]
texto_final_2017

```

##### Convert the text into a data frame 

In order to be able to analyze the text, we need to convert it into a structured data frame, where each line of speech has an identifier (line). This facilitates the following cleaning and analysis operations. As a result, we obtain a tibble with two columns: line (line number) and text (textual content).

```{r}

df_trump <- tibble(line = 1:length(texto_final_2017), text = texto_final_2017)

```

After having our tibble, we need to tokenize and clean the text. Tokenization and text cleaning are essential preprocessing steps in any text mining workflow. Tokenization involves breaking down the text into individual words, or tokens, which allows us to analyze the text at the word level. After tokenizing, we perform additional cleaning to remove elements that do not contribute meaningful information to the analysis. This includes removing common stopwords (such as "the", "and", "we"), which appear frequently but carry little semantic weight, and filtering out numerical values, which can introduce noise into the topic model. By focusing only on the most relevant words, we enhance the clarity and coherence of the topics that the LDA algorithm will later identify.

```{r}

df_words <- df_trump %>%
  unnest_tokens(word, text) %>%
  anti_join(get_stopwords()) %>%  # filter stopwords
  filter(!str_detect(word, "^[0-9]+$"))  # take out numbers 

```

As a result, we obtain a dataframe with columns line and word, which contains only significative and useful words.

Now that we have our data tokenized and cleaned, we need to convert it into a DTM format matrix in which rows are lines of speech, columns are words and values are the number of occurrences of each word. This matrix is the input needed by the LDA model. The result will be a DTM matrix with word counts per line.

```{r}

df_dtm <- df_words %>%
  count(line, word) %>%
  cast_dtm(document = line, term = word, value = n)

```

##### Apply LDA

Once we have our cleaned and tokenized text represented as a DTM, we can use LDA to uncover the hidden thematic structure within the text. LDA is a probabilistic generative model that assumes each document (in our case, each line of the speech) is a mixture of several topics, and each topic is characterized by a distribution over words. When we apply LDA, we specify the number of topics (k) that we want the algorithm to identify. Internally, the model iteratively estimates two probability distributions: the distribution of topics across documents (gamma), and the distribution of words across topics (beta). These distributions are computed using an optimization process that assigns words to topics in a way that maximizes the likelihood of the observed data. In this step, we also fix a random seed to ensure reproducibility. The main output of this step is the trained LDA model object, which contains all the information needed to interpret and visualize the topics. Specifically, we will later extract the most representative words for each topic (using beta) and the topic proportions for each document (using gamma), which will allow us to understand how different parts of the speech relate to the identified topics.

```{r}

lda_model <- LDA(df_dtm, k = 4, control = list(seed = 1234)) # Supposing we want to find 4 themes
 
```

Now that we have our LDA performed, we will use "matrix = "beta"" to extract the probability of a word given a theme. We will choose the 10 most representative words for each theme and we will visualize the results in a graph.  

```{r}
# Extract the most representative terms by topic
topics_terms <- tidy(lda_model, matrix = "beta")

# 10 most relevant words by theme 
top_terms <- topics_terms %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Visualization
top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Top 10 terms by theme",
       x = NULL, y = expression(beta))

```

In the visualization above each facet corresponds to a topic, and the length of the bars reflects the probability (β) that each word belongs to that topic. For example, in Topic 1, terms like great, america, country, and people are prominent, suggesting that this topic may relate to patriotic rhetoric and national pride. Topic 2 includes words such as us, must, american, states, and support, indicating a theme around collective action, duty, and perhaps military or international alliances. In Topic 3, terms like health, infrastructure, insurance, and government point toward domestic policy issues such as healthcare and public services. Topic 4 contains words such as immigration, system, believe, and nations, which likely refer to foreign policy and immigration reform. However, some overlapping terms like american and america appear across multiple topics, which may reduce topic distinctiveness. This overlap can be common in political speeches where key thematic words are repeated frequently. 

That is why, we will improve the quality of the topics identified. In this case, the graph shows some very repetitive and not very distinctive words that appear in several themes and do not help to differentiate well between them. We will go back to the cleanup step and manually remove frequent words that were not automatically removed, such as “america”, “american”, “must”, “one”, etc.; we will re-generate the DTM and re-apply the LDA model and test with different values of k to see if the topics are more coherent.

```{r}
# Personalized stopword list
custom_stopwords <- c("america", "american", "must", "just", "one", "new", "us", "like", "also", "now", "get", "even")

# Tokenization and cleaning
df_words_refined <- df_trump %>%
  unnest_tokens(word, text) %>%
  anti_join(get_stopwords()) %>%
  filter(!word %in% custom_stopwords) %>%
  filter(!str_detect(word, "^[0-9]+$"))

# Re-create DTM
df_dtm_refined <- df_words_refined %>%
  count(line, word) %>%
  cast_dtm(document = line, term = word, value = n)

# Apply LDA
lda_model_refined <- LDA(df_dtm_refined, k = 4, control = list(seed = 1234))

# Visualize new themes
topics_terms_refined <- tidy(lda_model_refined, matrix = "beta")

top_terms_refined <- topics_terms_refined %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms_refined %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Top 10 terms by topic (refined)",
       x = NULL, y = expression(beta))

```

The updated visualization reveals more coherent and meaningful themes compared to the initial version. After refining the preprocessing step and removing generic, high-frequency words like “america” and “american”, the model now produces topics with more distinct and interpretable vocabularies. For instance, Topic 1 includes terms such as great, country, health, administration, and citizens, suggesting a focus on national pride, governance, and public services. Topic 2, with words like every, world, year, united, and history, appears to address broader, possibly international or historical themes and global cooperation. Topic 3 is strongly characterized by the presence of words like system, immigration, create, and access, pointing towards themes of immigration reform, policy systems, and support initiatives. Finally, Topic 4 contains terms like terrorism, trade, respect, and allies, clearly reflecting concerns about foreign policy, international relations, and national security. Overall, this version of the model shows better topic separation and thematic clarity. 

We will also try different values of k, for example 3 or 5, to see if the topics are more consistent.

```{r}
# Change value of k and make the model again
k_values <- c(3, 5)

lda_models <- list()

for (k in k_values) {
  model <- LDA(df_dtm_refined, k = k, control = list(seed = 1234))
  lda_models[[as.character(k)]] <- model
}

# Try with k = 5
topics_terms_k5 <- tidy(lda_models[["5"]], matrix = "beta")

top_terms_k5 <- topics_terms_k5 %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms_k5 %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Top 10 terms by topic (k = 5)",
       x = NULL, y = expression(beta))

# Try with k = 3
topics_terms_k3 <- tidy(lda_models[["3"]], matrix = "beta")

top_terms_k3 <- topics_terms_k3 %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms_k3 %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Top 10 terms by topic (k = 3)",
       x = NULL, y = expression(beta))

```

When comparing the LDA models with k = 3 and k = 5, we observe noticeable differences in the specificity and interpretability of the topics. The model with k = 3 generates broader, more general topics. For instance, Topic 1 and Topic 2 include terms like country, people, world, and united, which overlap significantly and may reduce the semantic distinction between topics. Topic 3 in this model clusters words related to policy and immigration (system, immigration, help, create), but the grouping still feels somewhat mixed and less thematically tight. This model captures the overall themes of the speech, but the topics are somewhat diluted and less actionable for deeper insight.

In contrast, the k = 5 model presents more clearly defined topics, each centered around a specific aspect of the speech. For example, Topic 1 contains personal and ceremonial terms like tonight, thank, ryan, and great, suggesting emotional or introductory language. Topic 2 reflects economic and administrative themes (companies, tax, jobs, borders), while Topic 3 seems to highlight American citizens and support (help, choice, access). Topic 4 is strongly focused on immigration and security (terrorism, immigration, system, respect), and Topic 5 touches on diplomatic and visionary rhetoric (allies, believe, future, free). This greater topic resolution offers clearer insights into the structure and rhetoric of the speech, making k = 5 a more effective choice for interpretability in this context.

So, we decide to use the LDA model with k = 5 because it offers a clearer and more interpretable separation between topics. 

```{r}
lda_final <- lda_models[["5"]]

```

We will extract the top words for each topic again. 

```{r}
# Extract top words for each topic
topics_final <- tidy(lda_final, matrix = "beta") %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  arrange(topic, -beta)

# View table of top terms
topics_final %>%
  select(topic, term, beta) %>%
  knitr::kable() %>%
  kableExtra::kable_styling(full_width = FALSE)

```

So, although the interpretation of topics based on top terms has already been done, we can conclude that the main topics are:
1. Ceremonial and Governance
2. Economy and Policy
3. Support and Personal Appeals
4. Security and Immigration
5. Vision and Diplomacy

##### Assigning themes to each line of the speech

We will proceed by using the gamma matrix to identify which topic is most dominant in each line of the speech.

```{r}
# Topic probabilities for each document
doc_topics <- tidy(lda_final, matrix = "gamma")

# Get dominant topic per line
dominant_topic <- doc_topics %>%
  group_by(document) %>%
  slice_max(gamma, n = 1)

# Merge with original text
df_trump_topics <- df_trump %>%
  mutate(document = as.character(line)) %>%
  left_join(dominant_topic, by = "document")

```

We will create 3 different ways to visualize the results:

First we will view representative examples by theme. This will help understand qualitatively what type of content falls under each theme, also helping confirm that the topic assignments match their intended meaning. 

```{r}
# 3 representative lines by each topic
df_trump_topics %>%
  group_by(topic) %>%
  slice_sample(n = 3) %>%
  select(topic, text) %>%
  arrange(topic)

```

We will also analyze the frequence of each topic in the speech. This will tell us which topics dominate the speech. For example, if Topic 2 (Economy) has the most lines, that might suggest the economy was a central theme in this address.

```{r}
# Count how many lines are from each topic
df_trump_topics %>%
  count(topic) %>%
  ggplot(aes(x = factor(topic), y = n, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  labs(title = "Number of lines per topic", x = "Topic", y = "Line count")

```

Finally, we will watch the evolution of topics along the speech. This will help us analyze structure and flow. 

```{r}
# Change of topics all along the speech
df_trump_topics %>%
  mutate(line = as.numeric(document)) %>%
  ggplot(aes(x = line, y = topic, color = factor(topic))) +
  geom_point() +
  labs(title = "Topic flow throughout the speech", x = "Line number", y = "Topic")

```

After assigning the most likely topic to each line of President Trump’s 2017 speech, we examined the results and these are the results: 

The frequency analysis reveals that Topic 3 dominates the speech, followed by Topics 2 and 5, while Topic 4 is the least frequent. This suggests that the speech is heavily focused on citizen-related appeals, social policy, and support systems (Topic 3), along with economic and governmental issues (Topic 2), and visionary or diplomatic language (Topic 5). In contrast, security and immigration (Topic 4) occupies a smaller portion, indicating it was treated as a specific section rather than a recurring theme.

The topic progression plot shows how these themes unfold across the speech. Notably, the speech does not follow a strict thematic block structure. Instead, there is a scattered distribution, with topics appearing throughout in varying proportions. For example, Topic 1 (ceremonial and general statements) appears early and then reappears toward the end, which is consistent with how speeches often open and close with broad, unifying messages. Topic 3 is present across the entire speech, indicating a continuous effort to relate to individual citizens and emotional narratives. Topic 4, though less frequent, appears in mid-speech clusters, corresponding to sections on immigration and national security.

The sample lines per topic reinforce the thematic interpretations. Lines categorized under Topic 3 include phrases about helping Americans, improving access to healthcare, and personal stories — confirming it as a socially oriented, emotionally resonant topic. Topic 4 includes discussions about terrorism, borders, and immigration, aligning well with its security-driven vocabulary. Topics 1, 2, and 5 also maintain internal consistency in their sample texts, validating the model's accuracy.

Overall, thematic analysis of Trump’s 2017 State of the Union reveals a speech organized around recurring priorities, delivered in a clear and structured way. The five topics identified through LDA include themes such as ceremonial praise and American greatness, policy and legislative direction, support for American citizens, immigration and security concerns, and national vision in foreign affairs. The topic flow across the speech shows that Trump frequently transitions between these themes, creating a dynamic rhythm that blends emotion, persuasion, and political messaging. The distribution of topics reflects a speech focused on rallying national pride while addressing both domestic and global priorities. So, the thematic structure effectively supports the tone and political messaging of the address.

All in all, the topic modelling helped break down the speech into clear themes and showed how they’re spread across the text. It also made it easier to understand how Trump uses different topics to connect with the audience and deliver his message more effectively.

We will now proceed to do the same thing with the other 3 speeches we want to analyze, but we will make the explanation shorter, as we have already discussed everything in this first analysis. We will just replicate what has been done, in order to be able to compare the 4 speeches at the end. 

#### Trump 2025 speech

We first need to clean the text and make it in a suitable format for practising topic modeling. 

```{r}
# We remove the parts where the president was not talking
trump2025 <- read_lines("data/Trump_2025")

texto_filtrado_2025 <- trump2025 %>%
  str_subset("^(AUDIENCE|SPEAKER|VICE PRESIDENT|REPRESENTATIVE GREEN|SPEAKER jOHNSON)", negate = TRUE)
texto_filtrado_2025

# we remove the parenthesis
texto_filtrado <- texto_filtrado_2025 %>%
  str_replace_all("\\(.*?\\)", "")
texto_filtrado_2025

# we remove "THE PRESIDENT:"

texto_final_2025 <- str_replace(texto_filtrado_2025, "^THE PRESIDENT:\\s*", "")
texto_final_2025
# we remove empty rows
texto_final_2025 <- texto_final_2025[nchar(trimws(texto_final_2025)) > 0]
texto_final_2025
```

We will now convert it to a dataframe and apply tokenization. 

```{r}
# Convert into a dataframe
df_2025 <- tibble(line = 1:length(texto_final_2025), text = texto_final_2025)

# Tokenization and cleaning
df_words_2025 <- df_2025 %>%
  unnest_tokens(word, text) %>%
  anti_join(get_stopwords()) %>%               
  filter(!str_detect(word, "^[0-9]+$"))        

```

Now that we have our data tokenized and cleaned, we need to convert it into a DTM.

```{r}
df_dtm_2025 <- df_words_2025 %>%
  count(line, word) %>%
  cast_dtm(document = line, term = word, value = n)

```

Once we have our cleaned and tokenized text represented as a DTM, we can use LDA to uncover the hidden thematic structure within the text. We will use K = 5 in order to be able to compare all the speeches at the end. 

```{r}
lda_2025 <- LDA(df_dtm_2025, k = 5, control = list(seed = 1234))

```

Now that we have our LDA performed, we will use "matrix = "beta"" to extract the probability of a word given a theme. We will choose the 10 most representative words for each theme and we will visualize the results in a graph.

```{r}
# Extract the most representative terms by topic
topics_2025 <- tidy(lda_2025, matrix = "beta")

# 10 most relevant words by theme 
top_terms_2025 <- topics_2025 %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Visualization
top_terms_2025 %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Top 10 terms per topic (Trump 2025 Speech)",
       x = NULL, y = expression(beta))

```

In this case, several high-frequency words like “applause”, “it's”, and “going” appeared in multiple topics without adding real semantic value. Removing these can help the model focus on more meaningful content and improve the clarity and coherence of the topics, so, we need to create a custom list of stopwords and do the whole process again. 

```{r}
# List of customized stopwords
custom_stopwords <- c("applause", "it’s", "just", "also", "thank", "going", "we’re", 
                      "new", "get", "great", "now", "back", "first", "much", "want", "never", "he’s", "didn’t", "don’t", "they’re", "i’m") 

# CConvert into dataframe
df_2025_clean <- tibble(line = 1:length(texto_final_2025), text = texto_final_2025)

# Tokenization + cleaning
df_words_2025_clean <- df_2025_clean %>%
  unnest_tokens(word, text) %>%
  anti_join(get_stopwords()) %>%                         
  filter(!word %in% custom_stopwords) %>%                
  filter(!str_detect(word, "^[0-9]+$"))                  

```

We will now convert it into DTM and apply LDA again. 

```{r}
# Convert into DTM
df_dtm_2025_clean <- df_words_2025_clean %>%
  count(line, word) %>%
  cast_dtm(document = line, term = word, value = n)

# Apply LDA
lda_2025_clean <- LDA(df_dtm_2025_clean, k = 5, control = list(seed = 1234))

```

And we will recreate the visualization in order to see if the information obtained is more useful and informative. 

```{r}
# Extract the most representative terms by topic
topics_2025_clean <- tidy(lda_2025_clean, matrix = "beta")

# 10 most relevant words by theme
top_terms_2025_clean <- topics_2025_clean %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Visualization
top_terms_2025_clean %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Top 10 terms per topic (Trump 2025 – Improved Cleaning)",
       x = NULL, y = expression(beta))

```

The final version of Trump’s 2025 speech offers a well-structured and thematically clear breakdown. Topic 1 includes words like “years”, “tonight”, “members”, “history”, and “days”, which seem to relate to ceremonial references, past accomplishments, or commemorative remarks (possibly the opening of the speech or reflective segments). Topic 2 centers around “good”, “beautiful”, “job”, “luck”, and “hard”, indicating an optimistic tone focused on personal achievements, character traits, or positive evaluations of people and efforts. This likely reflects moments of praise or uplifting rhetoric. Topic 3 is characterized by “million”, “money”, “world”, “country”, “tax”, and “united states”, suggesting a strong emphasis on economic issues, national finances, and global positioning (themes common in economic and geopolitical sections of the speech). Topic 4 includes terms like “us”, “fight”, “make”, “money”, and “congress”, which indicate a call to action, national strength, and perhaps direct political challenges or legislative goals. Finally, Topic 5 stands out for including more unique and specific terms like “panama”, “roberto”, “canal”, and “administration”, hinting at a reference to foreign policy or a historical anecdote about international relations and infrastructure (likely a specific story or example included for rhetorical effect).

We will proceed by using the gamma matrix to identify which topic is most dominant in each line of the speech.

```{r}
# Gamma matrix
doc_topics_2025 <- tidy(lda_2025_clean, matrix = "gamma")

# Select dominant topic by line
dominant_topic_2025 <- doc_topics_2025 %>%
  group_by(document) %>%
  slice_max(gamma, n = 1)

# Join with discourse lines
df_trump_topics_2025 <- df_2025 %>%
  mutate(document = as.character(line)) %>%
  left_join(dominant_topic_2025, by = "document")

```

And we will visualize the results.

```{r}
# Representative examples by topic
df_trump_topics_2025 %>%
  group_by(topic) %>%
  slice_sample(n = 3) %>%  # 3 examples by topic
  select(topic, text) %>%
  arrange(topic)

# Number of lines per topic
df_trump_topics_2025 %>%
  count(topic) %>%
  ggplot(aes(x = factor(topic), y = n, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  labs(title = "Number of lines per topic", x = "Topic", y = "Line count")

# Topic evolution throughout the discourse
df_trump_topics_2025 %>%
  mutate(line = as.numeric(document)) %>%
  ggplot(aes(x = line, y = topic, color = factor(topic))) +
  geom_point() +
  labs(title = "Topic flow throughout the speech", x = "Line number", y = "Topic")

```

The topic assignment reveals a well-distributed thematic structure throughout the speech. From the bar chart, we can observe that Topics 2 and 3 are the most dominant, each appearing in over 70 lines. These likely represent the speech’s core themes—potentially centered on economy, job creation, or patriotic sentiments—depending on how they were previously interpreted. Topic 1 also has strong representation (around 55 lines), possibly related to commemorative or ceremonial aspects of the address. Topics 4 and 5 show slightly fewer occurrences but are still meaningfully present. Topic 4 could correspond to policy initiatives or calls to action, while Topic 5 may deal with foreign affairs or historical references, based on previous top term analysis. Interestingly, a few lines remain unclassified (NA). These are likely short or vague segments (“Thank you very much”), which don’t contain enough information for the LDA model to confidently assign them to a topic. 

The flow plot gives insight into the speech’s structure: We see that topics are interleaved throughout the text, rather than being grouped in large thematic blocks. This indicates that Trump frequently switches between themes, perhaps to maintain engagement or touch on multiple talking points in close succession. Topic 2 and Topic 3 appear consistently throughout, showing they are central pillars of the speech, while Topics 4 and 5 appear more sporadically.

The topic modeling results for Trump’s 2025 address point to a speech with a strong focus on values, security, and public reassurance. The five topics extracted reflect recurring themes like patriotic rhetoric and government action, economic concerns, emotional appeals and recognition of individuals, national security and border control, and America’s place in the world. Thematic flow is consistent throughout the speech, with repeated references to key ideas like prosperity, protection, and leadership. This back-and-forth between emotional storytelling and assertive policy language keeps the speech engaging while reinforcing Trump’s narrative style. Overall, the topic distribution captures the dual nature of the address—both performative and policy-driven.

With this being said and having analyzed Trump's speeches, we will now move on to Obama's speech. 

#### Obama 2013 speech 

We first need to clean the text and make it in a suitable format for practising topic modeling. 
```{r}
# We remove the parts where the president was not talking
obama2013 <- read_lines("data/Obama_2013")

texto_filtrado_2013 <- obama2013 %>%
  str_subset("^(AUDIENCE|SPEAKER|VICE PRESIDENT|REPRESENTATIVE GREEN|SPEAKER jOHNSON)", negate = TRUE)
texto_filtrado_2013

# we remove the parenthesis
texto_filtrado_2013 <- texto_filtrado_2013 %>%
  str_replace_all("\\(.*?\\)", "")
texto_filtrado_2013

# we remove "THE PRESIDENT:"

texto_final_2013 <- str_replace(texto_filtrado_2013, "^THE PRESIDENT:\\s*", "")
texto_final_2013
# we remove empty rows
texto_final_2013 <- texto_final_2013[nchar(trimws(texto_final_2013)) > 0]

texto_final_2013

```

We will now convert it to a dataframe and apply tokenization. 

```{r}
# Convert it to a dataframe
df_obama_2013 <- tibble(line = 1:length(texto_final_2013), text = texto_final_2013)

# Tokenization + cleaning
df_words_obama <- df_obama_2013 %>%
  unnest_tokens(word, text) %>%
  anti_join(get_stopwords()) %>%
  filter(!str_detect(word, "^[0-9]+$"))  

```

Now that we have our data tokenized and cleaned, we need to convert it into a DTM.

```{r}
df_dtm_obama <- df_words_obama %>%
  count(line, word) %>%
  cast_dtm(document = line, term = word, value = n)

```

Once we have our cleaned and tokenized text represented as a DTM, we can use LDA to uncover the hidden thematic structure within the text. We will use K = 5 in order to be able to compare all the speeches at the end. 

```{r}
lda_obama <- LDA(df_dtm_obama, k = 5, control = list(seed = 1234))

```

Now that we have our LDA performed, we will use "matrix = "beta"" to extract the probability of a word given a theme. We will choose the 10 most representative words for each theme and we will visualize the results in a graph.

```{r}

# Extract the most representative terms by topic
topics_obama <- tidy(lda_obama, matrix = "beta")

# 10 most relevant words by theme 
top_terms_obama <- topics_obama %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Visualization
top_terms_obama %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Top 10 terms per topic (Obama 2013)",
       x = NULL, y = expression(beta))

```

The results for President Obama’s speech appear thematically coherent and relatively well-balanced across the five topics. Topic 1 is dominated by terms like “energy”, “years”, “gas”, “power”, and “home”, suggesting a focus on energy policy, sustainability, and infrastructure. Topic 2, with terms such as “can”, “tonight”, “congress”, “jobs”, and “act”, reflects the persuasive and directive tone of the speech, particularly calls to legislative action or government cooperation. Topic 3 is clearly focused on employment and the economy, with words like “jobs”, “high”, “tax”, “education”, and “job”, making this theme highly relevant to middle-class concerns and recovery plans. Topic 4 contains terms like “time”, “cuts”, “work”, “need”, and “americans”, which likely reflects urgency in addressing fiscal responsibility or policy reform—possibly linked to the budget and deficit debates at the time. Topic 5 stands out with “vote”, “families”, “deserve”, “right”, and “must”, suggesting a civic-oriented or value-driven message, possibly touching on themes like voting rights, equality, and social justice.

We will proceed by using the gamma matrix to identify which topic is most dominant in each line of the speech.

```{r}
# Gamma matrix
obama_gamma <- tidy(lda_obama, matrix = "gamma")

# Select dominant topic for each line
dominant_topic_obama <- obama_gamma %>%
  group_by(document) %>%
  slice_max(gamma, n = 1)

# Merge with original text 
df_obama_topics <- df_obama_2013 %>%
  mutate(document = as.character(line)) %>%
  left_join(dominant_topic_obama, by = "document")

```

And we will visualize the results.

```{r}
# Representative examples by topic
df_obama_topics %>%
  group_by(topic) %>%
  slice_sample(n = 3) %>%  
  select(topic, text) %>%
  arrange(topic)

# Number of lines per topic
df_obama_topics %>%
  count(topic) %>%
  ggplot(aes(x = factor(topic), y = n, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  labs(title = "Number of lines per topic", x = "Topic", y = "Line count")

#Topic flow throughout the speech
df_obama_topics %>%
  mutate(line = as.numeric(document)) %>%
  ggplot(aes(x = line, y = topic, color = factor(topic))) +
  geom_point() +
  labs(title = "Topic flow throughout the speech", x = "Line number", y = "Topic")

```

The distribution of topics across the speech is fairly balanced, as shown in the bar chart. All five topics have a similar number of lines, suggesting that Obama structured his address to cover multiple key areas fairly evenly. From the sample lines per topic: Topic 1 includes lines about legal immigration, hardworking Americans, and national remembrance. This points to citizenship, values, and national unity. Topic 2 seems more oriented toward policy and legislative action, featuring words like “congress”, “act”, and “jobs”. Topic 3 has strong economic content: lines on job creation, infrastructure, manufacturing, and the Affordable Care Act. This clearly represents the economy and domestic programs. Topic 4 lines include budget-focused language such as “cuts”, “work”, “need”, and “time”, highlighting urgency and economic reform. Topic 5 involves more emotive and civic language (“vote”, “families”, “deserve”, “unfinished task”), signaling a call to civic responsibility and social justice. The flow plot shows that Obama alternates between topics rather than presenting them in large uninterrupted blocks. This kind of thematic interweaving suggests a rhetorical strategy that ties together different priorities—values, legislation, economy—within broader arguments.

Overall, thematic analysis of Obama’s 2013 State of the Union shows a well-structured and balanced speech, covering a range of key issues. The five topics identified through LDA span themes like immigration and national values, economic recovery and job creation, legislative action, fiscal reform, and civic responsibility. The flow of topics throughout the speech highlights Obama’s rhetorical strategy of revisiting core themes rather than isolating them into separate sections. This helps maintain coherence and momentum, while also reinforcing the connection between policy goals and American values. So, the topic distribution and progression align well with the broader tone and goals of the address.

We will move on to the last discourse, Biden's 2021 speech. 

#### Biden 2021 speech

We first need to clean the text and make it in a suitable format for practising topic modeling. 

```{r}
# We remove the parts where the president was not talking
biden2021 <- read_lines("data/Biden_2021")

texto_filtrado_2021 <- biden2021 %>%
  str_subset("^(AUDIENCE|SPEAKER|VICE PRESIDENT|REPRESENTATIVE GREEN|SPEAKER jOHNSON)", negate = TRUE)
texto_filtrado_2021

# we remove the parenthesis
texto_filtrado_2021 <- texto_filtrado_2021 %>%
  str_replace_all("\\(.*?\\)", "")
texto_filtrado_2021

# we remove "THE PRESIDENT:"

texto_final_2021 <- str_replace(texto_filtrado_2021, "^THE PRESIDENT:\\s*", "")
texto_final_2021
# we remove empty rows
texto_final_2021 <- texto_final_2021[nchar(trimws(texto_final_2021)) > 0]
texto_final_2021
```

We will now convert it to a dataframe and apply tokenization. 

```{r}
# Convert it to a dataframe
df_biden_2021 <- tibble(line = 1:length(texto_final_2021), text = texto_final_2021)

# Tokenization + cleaning
df_words_biden <- df_biden_2021 %>%
  unnest_tokens(word, text) %>%
  anti_join(get_stopwords()) %>%
  filter(!str_detect(word, "^[0-9]+$")) 
 

```

Now that we have our data tokenized and cleaned, we need to convert it into a DTM.

```{r}

df_dtm_biden <- df_words_biden %>%
  count(line, word) %>%
  cast_dtm(document = line, term = word, value = n)

```

Once we have our cleaned and tokenized text represented as a DTM, we can use LDA to uncover the hidden thematic structure within the text. We will use K = 5 in order to be able to compare all the speeches at the end. 

```{r}

lda_biden <- LDA(df_dtm_biden, k = 5, control = list(seed = 1234))

```

Now that we have our LDA performed, we will use "matrix = "beta"" to extract the probability of a word given a theme. We will choose the 10 most representative words for each theme and we will visualize the results in a graph.

```{r}

# Extract the most representative terms by topic
topics_biden <- tidy(lda_biden, matrix = "beta")

# 10 most relevant words by theme 
top_terms_biden <- topics_biden %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Visualization
top_terms_biden %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Top 10 terms per topic (Biden 2021)",
       x = NULL, y = expression(beta))

```

In this case, several high-frequency words like “we're”, “it's”, and “one” appeared in multiple topics without adding real semantic value. Removing these can help the model focus on more meaningful content and improve the clarity and coherence of the topics, so, we need to create a custom list of stopwords and do the whole process again. 

```{r}
biden_stopwords <- c("it’s", "we’re", "i’ve", "that’s", "let’s", "one", "just", "can", "said", "know", "ever", "get", "now", "also", "percent", "act", "america", "american")

# Convert into a tibble
df_biden_2021 <- tibble(line = 1:length(texto_final_2021), text = texto_final_2021)

# Tokenize +cleaning
df_words_biden <- df_biden_2021 %>%
  unnest_tokens(word, text) %>%
  filter(!word %in% biden_stopwords) %>%                     
  anti_join(get_stopwords()) %>%                          
  filter(!str_detect(word, "^[0-9]+$"))                    

# Create DTM
dtm_biden <- df_words_biden %>%
  count(line, word) %>%
  cast_dtm(document = line, term = word, value = n)

# LDA with  k = 5
lda_biden <- LDA(dtm_biden, k = 5, control = list(seed = 1234))

# Top terms per topic
top_terms_biden <- tidy(lda_biden, matrix = "beta") %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>%
  ungroup() %>%
  arrange(topic, -beta)

# Visualization
top_terms_biden %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  labs(title = "Top 10 terms per topic (Biden 2021 – Improved Cleaning)",
       x = NULL, y = expression(beta))


```

The refined output from Biden's 2021 speech shows a much clearer thematic structure. Topic 1 features terms like century, years, world, and tax, suggesting a focus on long-term planning and economic positioning of the U.S. in the 21st century. Topic 2, with words such as jobs, power, plan, change, and investments, clearly reflects economic recovery and industrial policy, a recurring theme in Biden's economic messaging. Topic 3 blends terms like families, care, jobs, and need, pointing toward social policy, healthcare, and family support. Topic 4, containing words like pass, congress, right, and pandemic, indicates legislative appeals and crisis response, likely tied to COVID-19 and civil rights discussions. Lastly, Topic 5 uses keywords such as people, democracy, gun, opportunity, and justice, all of which suggest a strong emphasis on American identity, civic values, and calls for unity. Overall, the model has successfully isolated key policy pillars of Biden’s speech—economic strategy, healthcare, legislative action, and democratic ideals—with clear differentiation between topics.

We will proceed by using the gamma matrix to identify which topic is most dominant in each line of the speech.

```{r}

# Gamma matrix
biden_topics <- tidy(lda_biden, matrix = "gamma")

# Select dominant topic for each line
biden_top_topic <- biden_topics %>%
  group_by(document) %>%
  slice_max(gamma) %>%
  ungroup()

# Merge with original text 
df_biden_assigned <- df_biden_2021 %>%
  mutate(document = as.character(line)) %>%
  inner_join(biden_top_topic, by = "document") %>%
  select(line, text, topic)

```

And we will visualize the results.

```{r}
# Representative examples by topic
df_biden_assigned %>%
  group_by(topic) %>%
  slice_head(n = 3) %>%  
  select(topic, text) %>%
  arrange(topic)

# Number of lines per topic
df_biden_assigned %>%
  count(topic) %>%
  ggplot(aes(x = factor(topic), y = n, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  labs(title = "Number of lines per topic (Biden 2021)",
       x = "Topic",
       y = "Line count")

#Topic flow throughout the speech
df_biden_assigned %>%
  ggplot(aes(x = line, y = topic, color = factor(topic))) +
  geom_point(size = 2) +
  labs(title = "Topic flow throughout the speech (Biden 2021)",
       x = "Line number",
       y = "Topic") +
  theme_minimal()

```

The topic model for President Biden’s 2021 speech reveals five distinct but interconnected themes. One of the key topics centers around policy and economic recovery, shown by terms like “jobs,” “plan,” and “families,” pointing to the administration’s emphasis on employment and pandemic relief. Another dominant topic revolves around legislative urgency and action, with words like “pass,” “congress,” and “right,” suggesting calls for cooperation in moving forward with bills. Additionally, “democracy,” “justice,” and “opportunity” indicate a broader theme around civil values and rebuilding trust in American institutions. Looking at the topic flow, we can see that the distribution of themes is relatively balanced, with each topic receiving significant attention throughout the speech. This suggests Biden aimed for an even rhetorical structure, frequently looping back to reinforce ideas rather than dividing the speech into rigid thematic blocks. The speech opens and closes with references to unity, democracy, and national resilience—helping to tie the more technical sections together with an overarching narrative about hope and collective responsibility.

Overall, thematic analysis of Biden’s 2021 address shows a speech grounded in resilience, recovery, and unity. The five topics identified reflect core priorities of the early Biden administration: economic renewal, legislative action, pandemic response, democratic values, and civic responsibility. These themes are interwoven throughout the speech, with none of them dominating excessively. This suggests a deliberate strategy to present a balanced narrative, where policy details are consistently linked to broader ideals. The topic flow shows that rather than separating ideas into distinct segments, Biden returns to key themes several times, reinforcing his message of rebuilding and national progress.

#### Speech comparison

We will now create a thematic comparison between the four speeches (Trump 2017, Trump 2025, Obama 2013 and Biden 2021) using a single LDA model. We will first unite all the texts in one dataframe. 

```{r}
# Create dataframes
df_trump2017 <- tibble(line = 1:length(texto_final_2017), text = texto_final_2017, president = "Trump 2017")
df_trump2025 <- tibble(line = 1:length(texto_final_2025), text = texto_final_2025, president = "Trump 2025")
df_obama2013 <- tibble(line = 1:length(texto_final_2013), text = texto_final_2013, president = "Obama 2013")
df_biden2021 <- tibble(line = 1:length(texto_final_2021), text = texto_final_2021, president = "Biden 2021")

# Unite in a single dataframe
df_all <- bind_rows(df_trump2017, df_trump2025, df_obama2013, df_biden2021) %>%
  mutate(document = paste(president, line, sep = "_"))  # ID único por línea

```

We will apply tokenization and cleaning. 

```{r}
# Personalized stopwords
general_stopwords <- c("it’s", "we’re", "i’ve", "that’s", "let’s", "one", "just", "can", "said", "know", "ever", "get", "now", "also", "percent", "act", "america", "american")

df_words_all <- df_all %>%
  unnest_tokens(word, text) %>%
  filter(!word %in% general_stopwords) %>%
  anti_join(get_stopwords()) %>%
  filter(!str_detect(word, "^[0-9]+$"))

```

We will proceed by creating a DTM and applying LDA. 

```{r}
# DTM
df_dtm_all <- df_words_all %>%
  count(document, word) %>%
  cast_dtm(document = document, term = word, value = n)

# LDA
lda_all <- LDA(df_dtm_all, k = 5, control = list(seed = 1234))

```

And we will visualize it. 

```{r}
# Extract gamma
gamma_all <- tidy(lda_all, matrix = "gamma") %>%
  separate(document, into = c("president", "line"), sep = "_")

# Calculate average ratio of each subject per president
gamma_summary <- gamma_all %>%
  group_by(president, topic) %>%
  summarise(mean_gamma = mean(gamma), .groups = "drop")

# Visualization
ggplot(gamma_summary, aes(x = president, y = mean_gamma, fill = factor(topic))) +
  geom_col(position = "fill") +
  labs(title = "Topic Distribution by President",
       x = "President",
       y = "Proportion of Topics",
       fill = "Topic") +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal()

```

The stacked bar chart shows how each president emphasized the five discovered topics in their speeches. Biden’s 2021 address displays the most balanced distribution among all five topics, with Topic 1 (possibly international affairs and future vision) being slightly more dominant. Obama’s 2013 speech stands out for its stronger focus on Topic 3, which may relate to job creation, economic recovery, or education. Meanwhile, Trump’s 2017 and 2025 speeches share very similar proportions, though the 2025 speech places noticeably more weight on Topic 5, potentially reflecting themes like national identity, patriotism, or calls for unity. Interestingly, Topic 4, which could involve policy initiatives or legislative action, seems more present in Trump’s 2017 speech than in Obama’s or Biden’s. This might highlight how Trump used his first address to stress concrete policy rollouts.

We can also try to make a comparison between the 4 speeches with: 

```{r}
# Numerical summary of how much each topic appears across each speech
topic_summary <- gamma_all %>%
  group_by(president, topic) %>%
  summarise(avg_gamma = mean(gamma)) %>%
  arrange(president, topic)

print(topic_summary)

# Spread topic proportions by president
topic_matrix <- topic_summary %>%
  tidyr::pivot_wider(names_from = topic, values_from = avg_gamma, values_fill = 0) %>%
  column_to_rownames("president")

# Compute cosine similarity
similarity_matrix <- as.matrix(dist(topic_matrix, method = "cosine"))
print(round(1 - similarity_matrix, 2))  # 1 - distance = similarity

```

The average gamma values indicate how dominant each topic is within a president's speech. Biden's 2021 speech shows a fairly balanced distribution, with Topic 1 (possibly about future-oriented themes and national identity) being slightly more dominant, followed by Topics 3 and 4. Obama’s 2013 speech has a clear emphasis on Topic 3, which could relate to jobs and economic recovery, suggesting a stronger thematic focus on domestic policy. Trump’s 2017 speech shows Topic 4 as the most dominant, while his 2025 speech places the greatest weight on Topic 5 — hinting at a shift in focus from economic or institutional matters (2017) to perhaps more emotional or populist themes (2025).

The cosine similarity matrix tells us how similar the overall topic proportions are between the four speeches. The highest similarity (0.98) is between Biden 2021 and Trump 2017, which is surprising and suggests a shared focus on similar topics — possibly due to overlapping concerns like recovery, unity, or economic plans. Trump 2025 shows strong similarity to Trump 2017 (0.95), indicating internal thematic consistency. Obama 2013 is slightly less similar to all others (values between 0.87 and 0.95), confirming that his speech emphasized different thematic priorities.

Despite being from different parties and eras, all four speeches share a foundational structure — touching on governance, economic concerns, and national identity. However, subtle shifts can be detected: Obama’s speech leans more heavily into economic rebuilding and policy implementation, while Trump’s speeches evolve from institutional goals to more emotionally driven appeals. Biden’s position seems to blend these elements, aiming for a unifying message that echoes both continuity and reform.

We can also make a comparison with the betas to compare which words are most associated with each topic for each president:

```{r}

# Extract beta for each model
beta_biden <- tidy(lda_biden, matrix = "beta") %>% mutate(president = "Biden 2021")
beta_obama <- tidy(lda_obama, matrix = "beta") %>% mutate(president = "Obama 2013")
beta_trump2017 <- tidy(lda_model_refined, matrix = "beta") %>% mutate(president = "Trump 2017")
beta_trump2025 <- tidy(lda_2025_clean, matrix = "beta") %>% mutate(president = "Trump 2025")

# Combine all into a single table
beta_all <- bind_rows(beta_biden, beta_obama, beta_trump2017, beta_trump2025)


top_terms_by_president <- beta_all %>%  # assuming you have all beta values in `beta_all`
  group_by(president, topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

ggplot(top_terms_by_president, aes(x = reorder(term, beta), y = beta, fill = president)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ president + topic, scales = "free", ncol = 5) +
  coord_flip() +
  labs(title = "Top Terms per Topic and President",
       x = "Term", y = "Beta (Word Probability)")

```

Topic 1 appears to focus on temporal or national framing (words like “years,” “world,” “century,” “energy,” “country”). Biden and Obama use temporal markers like “century” and “years” more heavily, whereas Trump 2017 emphasizes “people” and “country,” and Trump 2025 introduces less semantically rich terms like “tonight” and “members.” This suggests that Biden and Obama frame their discourse within broader historical or national narratives, while Trump’s tone is more anchored in people and immediacy. Topic 2 emphasizes legislative or executive action — terms like “jobs,” “act,” “congress,” “plan,” “president.” Biden leads with “jobs” and “plan,” showing a proactive, policy-driven agenda. Obama includes “congress,” “can,” and “tonight,” indicating direct appeals for action. Trump 2017 uses “today,” “world,” and “nation” to ground his points in current national challenges. Trump 2025's focus shifts to adjectives like “good” and “beautiful,” reflecting a more rhetorical or persuasive tone rather than action-based content.

Topic 3 contains terms related to economic or systemic issues (“work,” “tax,” “system,” “country,” “nation,” “immigration”). Obama emphasizes economic concerns (“jobs,” “high,” “tax”), while Biden highlights social policy (“families,” “care,” and “plan”). Trump 2017’s emphasis on “immigration,” “system,” and “access” aligns with his strong rhetoric on national security and structural change. Trump 2025 is more subdued, with “million” and “people” suggesting a populist or budget-driven framing. Topic 4 seems linked to governance, rights, and institutions — words like “congress,” “pass,” “right,” “pandemic,” “department,” “fight,” etc. Biden's top terms like “congress,” “pass,” and “americans” signal a legislative focus with civic responsibility. Obama focuses more on urgency and moral reasoning (“need,” “get,” “make”), while Trump 2017 features “department,” “country,” and “terrorists,” suggesting a national security tone. Trump 2025 emphasizes action and resistance with “fight,” “make,” “ever,” and “american.” Topic 5 is rooted in democratic values and collective identity — with “democracy,” “people,” “justice,” “lives,” “citizens,” “families,” “vote.” Biden uses strong democratic markers like “democracy,” “justice,” “opportunity.” Obama emphasizes “vote,” “families,” “deserve” — reinforcing civic engagement. Trump 2017's terms are less emotionally charged (“across,” “today,” “nation”), and Trump 2025 again returns to general patriotic terms like “country,” “us,” and “ever.” This shows how Trump leans more on nationalism than explicitly democratic ideals.

#### General topic modeling discussion

Although this comparison can give us clear information differences, we will try to compare each president's speeches in a more separate way. First, when comparing Trump’s 2017 and 2025 speeches, one of the most striking differences lies in the dominant topics and how they are introduced throughout the speech. In 2017, Trump's address focused heavily on national security, immigration, and economic revitalization, with clear references to restoring borders, protecting American workers, and bringing manufacturing back to the U.S. These topics appeared in a structured pattern throughout the speech, giving a sense of control and alignment with his "America First" platform. By contrast, the 2025 speech, while still retaining a populist tone, appeared slightly more fragmented, with greater emphasis on broad themes such as national identity, citizen stories, and social appeals. This shift suggests a subtle change in rhetorical strategy (from implementation of promises to reflecting on outcomes and reinforcing emotional appeal).

In terms of topic flow, the 2017 speech demonstrated more distinct topic blocks, with each section clearly dedicated to a different policy domain, including healthcare, military, and economic policy. This segmentation gave the speech a more organized and agenda-driven structure. The 2025 speech, on the other hand, showed a more interwoven flow of topics, often mixing references to personal stories, political achievements, and calls for unity within the same segments. This may indicate an attempt to appeal to a broader audience or to reflect a matured presidential persona that integrates policies within a larger national narrative. Another noteworthy point is the emotional tone. Trump’s 2017 speech, while firm and assertive, maintained a business-like delivery that aligned with his image as an outsider entering politics to "clean up Washington." The language in the 2025 speech, however, leaned more heavily into emotional and patriotic appeals, with a notable increase in references to individuals, values, and legacy. This emotional shift could be interpreted as an effort to consolidate public support and present his leadership in a more reflective, almost legacy-defining light — something typical in second-term narratives or late-career rhetoric.  Finally, when looking at the vocabulary and keywords driving the topic models, we observe that terms in the 2017 speech were more policy-oriented ("jobs," "tax," "border," "security"), whereas the 2025 topics included words like "people," "freedom," "back," and "great," suggesting a move toward symbolism and shared identity rather than just concrete legislative goals. This linguistic change further supports the idea that Trump’s later speech pivoted from promises and plans to affirming a collective narrative, possibly to shape public memory of his administration.

Second, when comparing Trump with Obama, the contrast in rhetorical structure and thematic distribution becomes even more pronounced. Obama’s 2013 State of the Union address demonstrated a high degree of topical coherence, with economic recovery and legislative priorities being dominant. His speech emphasized forward-thinking policies (green energy, education reform) and maintained a tone of measured optimism. In contrast, Trump’s speeches, especially in 2017, focused more on disruption and change, using sharper, more action-oriented language to underline a break from previous administrations. This difference highlights a broader ideological contrast: Obama positioned himself as a unifier and reformer, while Trump framed himself as a reformer through confrontation. Another point of difference is how both presidents framed national identity and values. Obama’s discourse often integrated diversity, inclusivity, and opportunity as core American values, whereas Trump centered his discourse around sovereignty, protectionism, and strength. This is evident in the dominant topics from their respective models — where Obama’s speech frequently referred to “families,” “education,” “jobs,” and “future,” Trump’s top terms included “border,” “order,” “enforcement,” and “America First.” These contrasting priorities reflect not just different political agendas but also different visions of American society.

Third, when comparing Trump and Biden, the difference lies not only in content but also in tone and topic integration. Biden’s 2021 speech featured a balanced topic flow, with equal attention given to recovery (post-pandemic), democracy, healthcare, and unity. The emotional register was empathetic and often invoked shared struggle and resilience, contrasting with Trump’s assertive and goal-focused tone. Biden's speech made frequent use of collective pronouns ("we," "our") and framed policy as a collaborative national effort, whereas Trump’s speeches often leaned into "I" and "they," underscoring personal leadership and external threats.

Lastly, from a structural perspective, Biden’s and Obama’s speeches show a higher tendency to weave personal stories into policy discussions, using them to illustrate larger political points. Trump, while also invoking citizen stories, tended to use them more as testimonies of government success or political justification rather than vehicles for empathy. This rhetorical contrast is also evident in the distribution and transitions between topics: Biden and Obama frequently revisited themes throughout their speeches to build cohesion, while Trump more often maintained strong thematic clusters, particularly in the 2017 address. This makes Trump’s speeches feel more segmented, while Obama’s and Biden’s come across as narratively fluid.

Overall, the topic modeling analysis across the four presidential speeches highlights how each leader shaped their message to reflect their political priorities and the context of their presidency. Trump’s speeches leaned toward strong national identity, economic protectionism, and bold rhetoric, while Obama emphasized hope, reform, and collective responsibility. Biden's speech blended crisis recovery with unity and democratic values. So, while there are thematic overlaps, each speech reflects a unique rhetorical strategy and vision for the country.

## Conclusion
